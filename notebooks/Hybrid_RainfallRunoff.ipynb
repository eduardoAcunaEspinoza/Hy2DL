{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**General Description**\n",
    "\n",
    "The following notebook contains the code to create, train, validate, and test a rainfall-runoff model using an LSTM network architecture. The notebook support running experiments in different large-sample hydrology datasets including: CAMELS-GB, CAMELS-US, CAMELS-DE. The details for each dataset can be read from a .yml file.\n",
    "\n",
    "***Authors:***\n",
    "- Eduardo Acuña Espinoza (eduardo.espinoza@kit.edu)\n",
    "- Manuel Alvarez Chaves (manuel.alvarez-chaves@simtech.uni-stuttgart.de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import datetime\n",
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "# Import classes and functions from other files\n",
    "from hy2dl.datasetzoo import get_dataset\n",
    "from hy2dl.evaluation.metrics import nse\n",
    "from hy2dl.modelzoo import get_model\n",
    "from hy2dl.training.loss import nse_basin_averaged\n",
    "from hy2dl.utils.config import Config\n",
    "from hy2dl.utils.optimizer import Optimizer\n",
    "from hy2dl.utils.utils import set_random_seed, upload_to_device\n",
    "\n",
    "# colorblind friendly palette\n",
    "color_palette = {\"observed\": \"#377eb8\", \"simulated\": \"#4daf4a\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1. Initialize information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to .yml file where the experiment settings are stored. The experimet settings can also be defined manually as a\n",
    "# dictionary.\n",
    "path_experiment_settings = \"../examples/hybrid_camels_us.yml\"\n",
    "\n",
    "# Read experiment settings\n",
    "config = Config(path_experiment_settings)\n",
    "config.init_experiment()\n",
    "config.dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2. Create datasets and dataloaders used to train/validate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset class\n",
    "Dataset = get_dataset(config)\n",
    "\n",
    "# Dataset training\n",
    "config.logger.info(f\"Loading training data from {config.dataset} dataset\")\n",
    "total_time = time.time()\n",
    "\n",
    "training_dataset = Dataset(cfg=config, time_period=\"training\")\n",
    "\n",
    "training_dataset.calculate_basin_std()\n",
    "training_dataset.calculate_global_statistics(save_scaler=True)\n",
    "training_dataset.standardize_data(standardize_output=False)\n",
    "\n",
    "config.logger.info(f\"Number of entities with valid samples: {len(training_dataset.df_ts)}\")\n",
    "config.logger.info(\n",
    "    f\"Time required to process {len(training_dataset.df_ts)} entities: \"\n",
    "    f\"{datetime.timedelta(seconds=int(time.time() - total_time))}\"\n",
    ")\n",
    "config.logger.info(f\"Number of valid training samples: {len(training_dataset)}\\n\")\n",
    "\n",
    "# Dataloader training\n",
    "train_loader = DataLoader(\n",
    "    dataset=training_dataset,\n",
    "    batch_size=config.batch_size_training,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    collate_fn=training_dataset.collate_fn,\n",
    "    num_workers=config.num_workers,\n",
    ")\n",
    "\n",
    "# Print details of a loader´s sample to check that the format is correct\n",
    "config.logger.info(\"Details training dataloader\".center(60, \"-\"))\n",
    "config.logger.info(f\"Batch structure (number of batches: {len(train_loader)})\")\n",
    "config.logger.info(f\"{'Key':^30}|{'Shape':^30}\")\n",
    "# Loop through the sample dictionary and print the shape of each element\n",
    "for key, value in next(iter(train_loader)).items():\n",
    "    if key.startswith((\"x_d\", \"x_conceptual\")):\n",
    "        config.logger.info(f\"{key}\")\n",
    "        for i, v in value.items():\n",
    "            config.logger.info(f\"{i:^30}|{str(v.shape):^30}\")\n",
    "    else:\n",
    "        config.logger.info(f\"{key:<30}|{str(value.shape):^30}\")\n",
    "\n",
    "config.logger.info(\"\")  # prints a blank line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset validation\n",
    "config.logger.info(f\"Loading validation data from {config.dataset} dataset\")\n",
    "total_time = time.time()\n",
    "\n",
    "validation_dataset = Dataset(cfg=config, time_period=\"validation\")\n",
    "\n",
    "validation_dataset.calculate_basin_std()\n",
    "validation_dataset.scaler = training_dataset.scaler\n",
    "validation_dataset.standardize_data(standardize_output=False)\n",
    "\n",
    "config.logger.info(f\"Number of entities with valid samples: {len(validation_dataset.df_ts)}\")\n",
    "config.logger.info(\n",
    "    f\"Time required to process {len(validation_dataset.df_ts)} entities: \"\n",
    "    f\"{datetime.timedelta(seconds=int(time.time() - total_time))}\"\n",
    ")\n",
    "config.logger.info(f\"Number of valid validation samples: {len(validation_dataset)}\\n\")\n",
    "\n",
    "# Dataloader training\n",
    "validation_loader = DataLoader(\n",
    "    dataset=validation_dataset,\n",
    "    batch_size=config.batch_size_training,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    collate_fn=validation_dataset.collate_fn,\n",
    "    num_workers=config.num_workers,\n",
    ")\n",
    "\n",
    "# Print details of a loader´s sample to check that the format is correct\n",
    "config.logger.info(\"Details validation dataloader\".center(60, \"-\"))\n",
    "config.logger.info(f\"Batch structure (number of batches: {len(validation_loader)})\")\n",
    "config.logger.info(f\"{'Key':^30}|{'Shape':^30}\")\n",
    "# Loop through the sample dictionary and print the shape of each element\n",
    "for key, value in next(iter(validation_loader)).items():\n",
    "    if key.startswith((\"x_d\", \"x_conceptual\")):\n",
    "        config.logger.info(f\"{key}\")\n",
    "        for i, v in value.items():\n",
    "            config.logger.info(f\"{i:^30}|{str(v.shape):^30}\")\n",
    "    else:\n",
    "        config.logger.info(f\"{key:<30}|{str(value.shape):^30}\")\n",
    "\n",
    "config.logger.info(\"\")  # prints a blank line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 3. Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "set_random_seed(cfg=config)\n",
    "model = get_model(config).to(config.device)\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = Optimizer(cfg=config, model=model)\n",
    "\n",
    "# Training report structure\n",
    "config.logger.info(\"Training model\".center(60, \"-\"))\n",
    "config.logger.info(f\"{'':^16}|{'Trainining':^21}|{'Validation':^21}|\")\n",
    "config.logger.info(f\"{'Epoch':^5}|{'LR':^10}|{'Loss':^10}|{'Time':^10}|{'Metric':^10}|{'Time':^10}|\")\n",
    "\n",
    "total_time = time.time()\n",
    "# Loop through epochs\n",
    "for epoch in range(1, config.epochs + 1):\n",
    "    train_time = time.time()\n",
    "    loss_evol = []\n",
    "    # Training -------------------------------------------------------------------------------------------------------\n",
    "    model.train()\n",
    "    # Loop through the different batches in the training dataset\n",
    "    iterator = tqdm(\n",
    "        train_loader, desc=f\"Epoch {epoch}/{config.epochs}. Training\", unit=\"batches\", ascii=True, leave=False\n",
    "    )\n",
    "\n",
    "    for idx, sample in enumerate(iterator):\n",
    "        # reach maximum iterations per epoch\n",
    "        if config.max_updates_per_epoch is not None and idx >= config.max_updates_per_epoch:\n",
    "            break\n",
    "\n",
    "        sample = upload_to_device(sample, config.device)  # upload tensors to device\n",
    "        optimizer.optimizer.zero_grad()  # sets gradients to zero\n",
    "\n",
    "        # Forward pass of the model\n",
    "        pred = model(sample)\n",
    "        # Calcuate loss\n",
    "        loss = nse_basin_averaged(\n",
    "            y_sim=pred[\"y_hat\"],\n",
    "            y_obs=sample[\"y_obs\"],\n",
    "            per_basin_target_std=sample[\"std_basin\"]\n",
    "        )\n",
    "\n",
    "        # Backpropagation (calculate gradients)\n",
    "        loss.backward()\n",
    "\n",
    "        # Update model parameters (e.g, weights and biases)\n",
    "        optimizer.clip_grad_and_step(epoch, idx)\n",
    "\n",
    "        # Keep track of the loss per batch\n",
    "        loss_evol.append(loss.item())\n",
    "        iterator.set_postfix({\"loss\": f\"{np.mean(loss_evol):.3f}\"})\n",
    "\n",
    "        # remove elements from cuda to free memory\n",
    "        del sample, pred\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # training report\n",
    "    report = (\n",
    "        f\"{epoch:^5}|\"\n",
    "        f\"{optimizer.optimizer.param_groups[0]['lr']:^10.5f}|\"\n",
    "        f\"{np.mean(loss_evol):^10.3f}|\"\n",
    "        f\"{str(datetime.timedelta(seconds=int(time.time() - train_time))):^10}|\"\n",
    "    )\n",
    "\n",
    "    # Validation -----------------------------------------------------------------------------------------------------\n",
    "    if epoch % config.validate_every == 0:\n",
    "        val_time = time.time()\n",
    "        loss_evol = []\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            iterator = tqdm(\n",
    "                validation_loader,\n",
    "                desc=f\"Epoch {epoch}/{config.epochs}. Validation\",\n",
    "                unit=\"batches\",\n",
    "                ascii=True,\n",
    "                leave=False,\n",
    "            )\n",
    "\n",
    "            for idx, sample in enumerate(iterator):\n",
    "                # reach maximum iterations per epoch\n",
    "                if config.max_updates_per_epoch is not None and idx >= config.max_updates_per_epoch:\n",
    "                    break\n",
    "\n",
    "                sample = upload_to_device(sample, config.device)\n",
    "                pred = model(sample)\n",
    "                loss = nse_basin_averaged(\n",
    "                    y_sim=pred[\"y_hat\"], y_obs=sample[\"y_obs\"], per_basin_target_std=sample[\"std_basin\"]\n",
    "                )\n",
    "\n",
    "                loss_evol.append(loss.item())\n",
    "                del sample, pred\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "            # average loss validation\n",
    "            report += f\"{np.mean(loss_evol):^10.3f}|{str(datetime.timedelta(seconds=int(time.time() - val_time))):^10}|\"\n",
    "\n",
    "    # No validation\n",
    "    else:\n",
    "        report += f\"{'':^10}|{'':^10}|\"\n",
    "\n",
    "    # Print report and save model\n",
    "    config.logger.info(report)\n",
    "    torch.save(model.state_dict(), config.path_save_folder / \"model\" / f\"model_epoch_{epoch}\")\n",
    "    # modify learning rate\n",
    "    optimizer.update_optimizer_lr(epoch=epoch)\n",
    "\n",
    "# print total training time\n",
    "config.logger.info(f\"Total training time: {datetime.timedelta(seconds=int(time.time() - total_time))} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 4. Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case I already trained an LSTM I can re-construct the model. I just need to define the epoch for which I want to\n",
    "# re-construct the model\n",
    "# model = get_model(config).to(config.device)\n",
    "# model.load_state_dict(torch.load(config.path_save_folder / \"model\" / \"model_epoch_20\", map_location=config.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read previously generated scaler\n",
    "with open(config.path_save_folder / \"scaler.pickle\", \"rb\") as file:\n",
    "    scaler = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When we run our evalation period (validation or testing), we want to differentiate between basins. Therefore, each\n",
    "# batch entity will contain the whole time period (validation or testing) of a specific basin. For this, we will modify\n",
    "# seq_length and the predict_last_n.\n",
    "warmup_start_date = pd.to_datetime(config.testing_period[0], format=\"%Y-%m-%d\") - pd.DateOffset(\n",
    "    config.seq_length - config.predict_last_n\n",
    ")\n",
    "\n",
    "evaluation_seq_length = (pd.to_datetime(config.testing_period[1], format=\"%Y-%m-%d\") - warmup_start_date).days + 1\n",
    "evaluation_predict_last_n = evaluation_seq_length - config.predict_last_n\n",
    "\n",
    "# Update variables in config (this is just for the testing part. One need to change it back, or read the original config\n",
    "# in case training settings are required again)\n",
    "config.seq_length = evaluation_seq_length\n",
    "config.predict_last_n = evaluation_predict_last_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset validation\n",
    "config.logger.info(f\"Loading testing data from {config.dataset} dataset\")\n",
    "total_time = time.time()\n",
    "\n",
    "testing_dataset = Dataset(cfg=config, time_period=\"testing\", check_NaN=False)\n",
    "\n",
    "testing_dataset.scaler = scaler\n",
    "testing_dataset.standardize_data(standardize_output=False)\n",
    "\n",
    "config.logger.info(f\"Number of entities with valid samples: {len(testing_dataset.df_ts)}\")\n",
    "config.logger.info(\n",
    "    \"Time required to process {} entities: {}\".format(\n",
    "        len(testing_dataset.df_ts), datetime.timedelta(seconds=int(time.time() - total_time))\n",
    "    )\n",
    ")\n",
    "config.logger.info(f\"Number of valid testing samples: {len(testing_dataset)}\\n\")\n",
    "\n",
    "# Dataloader training\n",
    "test_loader = DataLoader(\n",
    "    dataset=testing_dataset,\n",
    "    batch_size=config.batch_size_evaluation,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    collate_fn=testing_dataset.collate_fn,\n",
    "    num_workers=config.num_workers,\n",
    ")\n",
    "\n",
    "# Print details of a loader´s sample to check that the format is correct\n",
    "config.logger.info(\"Details testing dataloader\".center(60, \"-\"))\n",
    "config.logger.info(f\"Batch structure (number of batches: {len(test_loader)})\")\n",
    "config.logger.info(f\"{'Key':^30}|{'Shape':^30}\")\n",
    "# Loop through the sample dictionary and print the shape of each element\n",
    "for key, value in next(iter(test_loader)).items():\n",
    "    if key.startswith((\"x_d\", \"x_conceptual\")):\n",
    "        config.logger.info(f\"{key}\")\n",
    "        for i, v in value.items():\n",
    "            config.logger.info(f\"{i:^30}|{str(v.shape):^30}\")\n",
    "    else:\n",
    "        config.logger.info(f\"{key:<30}|{str(value.shape):^30}\")\n",
    "\n",
    "config.logger.info(\"\")  # prints a blank line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing ----------------------------------------------------------------------\n",
    "config.logger.info(\"Testing model\".center(60, \"-\"))\n",
    "total_time = time.time()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_results = {}\n",
    "    iterator = tqdm(test_loader, desc=\"Testing\", unit=\"basins\", ascii=True)\n",
    "    for sample in iterator:\n",
    "        sample = upload_to_device(sample, config.device)\n",
    "        pred = model(sample)\n",
    "\n",
    "        # join results in a dataframe and store them in a dictionary (is easier to plot later)\n",
    "        for i in range(pred[\"y_hat\"].shape[0]):\n",
    "            df_discharge = pd.DataFrame(\n",
    "                data={\n",
    "                    \"y_obs\": sample[\"y_obs\"][i, :, 0].flatten().cpu().detach(),\n",
    "                    \"y_sim\": pred[\"y_hat\"][i, :, 0].flatten().cpu().detach(),\n",
    "                },\n",
    "                index=pd.to_datetime(sample[\"date\"][i, :].flatten()),\n",
    "            )\n",
    "\n",
    "            # extract internal_state (buckets) information\n",
    "            internal_states = {\n",
    "                key: value[i, :, :].squeeze(0).cpu().detach() for key, value in pred[\"internal_states\"].items()\n",
    "            }\n",
    "\n",
    "            # extract parameter  information\n",
    "            parameters = {key: value[i, :, :].squeeze(0).cpu().detach() for key, value in pred[\"parameters\"].items()}\n",
    "\n",
    "            test_results[sample[\"basin\"][i]] = {\n",
    "                \"discharges\": df_discharge,\n",
    "                \"internal_states\": internal_states,\n",
    "                \"parameters\": parameters,\n",
    "            }\n",
    "\n",
    "        # remove from cuda\n",
    "        del sample, pred\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "# Save results as a pickle file\n",
    "with open(config.path_save_folder / \"test_results.pickle\", \"wb\") as f:\n",
    "    pickle.dump(test_results, f)\n",
    "\n",
    "config.logger.info(f\"Total testing time: {datetime.timedelta(seconds=int(time.time() - total_time))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 5. Initial analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discharges = {key: value[\"discharges\"] for key, value in test_results.items()}\n",
    "loss_testing = nse(df_results=discharges, average=False)\n",
    "df_NSE = pd.DataFrame(data={\"basin_id\": list(test_results.keys()), \"NSE\": np.round(loss_testing, 3)})\n",
    "df_NSE = df_NSE.set_index(\"basin_id\")\n",
    "\n",
    "# Plot the histogram\n",
    "plt.hist(df_NSE[\"NSE\"], bins=[0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])\n",
    "\n",
    "# Add NSE statistics to the plot\n",
    "plt.text(\n",
    "    0.01,\n",
    "    0.8,\n",
    "    (\n",
    "        f\"Mean: {'%.2f' % df_NSE['NSE'].mean():>7}\\n\"\n",
    "        f\"Median: {'%.2f' % df_NSE['NSE'].median():>0}\\n\"\n",
    "        f\"Max: {'%.2f' % df_NSE['NSE'].max():>9}\\n\"\n",
    "        f\"Min: {'%.2f' % df_NSE['NSE'].min():>10}\"\n",
    "    ),\n",
    "    transform=plt.gca().transAxes,\n",
    "    bbox=dict(facecolor=\"white\", alpha=0.5),\n",
    ")\n",
    "\n",
    "# Format plot\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 5)\n",
    "plt.xlabel(\"NSE\", fontsize=12, fontweight=\"bold\")\n",
    "plt.ylabel(\"Frequency\", fontsize=12, fontweight=\"bold\")\n",
    "plt.title(\"NSE Histogram\", fontsize=16, fontweight=\"bold\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot simulated and observed discharges\n",
    "basin_to_analyze = random.sample(list(test_results.keys()), 1)[0]\n",
    "\n",
    "plt.figure(figsize=(20, 7))\n",
    "plt.plot(test_results[basin_to_analyze][\"discharges\"][\"y_obs\"], label=\"observed\", color=color_palette[\"observed\"])\n",
    "plt.plot(\n",
    "    test_results[basin_to_analyze][\"discharges\"][\"y_sim\"],\n",
    "    label=\"simulated\",\n",
    "    alpha=0.5,\n",
    "    color=color_palette[\"simulated\"],\n",
    ")\n",
    "\n",
    "# Format plot\n",
    "plt.xlabel(\"Date\", fontsize=12, fontweight=\"bold\")\n",
    "plt.ylabel(\"Discharge [mm/d]\", fontsize=12, fontweight=\"bold\")\n",
    "plt.title(\"Modeling results\", fontsize=16, fontweight=\"bold\")\n",
    "plt.tick_params(axis=\"both\", which=\"major\", labelsize=12)\n",
    "plt.legend(loc=\"upper right\", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot states\n",
    "state_of_interest = random.sample(list(test_results[basin_to_analyze][\"internal_states\"].keys()), 1)[0]\n",
    "\n",
    "states = test_results[basin_to_analyze][\"internal_states\"][state_of_interest]\n",
    "\n",
    "for i in range(states.shape[1]):\n",
    "    plt.plot(\n",
    "        test_results[basin_to_analyze][\"discharges\"][\"y_obs\"].index,\n",
    "        states[:, i],\n",
    "        label=state_of_interest + \"_\" + str(i + 1),\n",
    "    )\n",
    "\n",
    "# Adding labels and legend\n",
    "plt.xlabel(\"Date\", fontsize=12, fontweight=\"bold\")\n",
    "plt.ylabel(f\"{state_of_interest}\", fontsize=12, fontweight=\"bold\")\n",
    "plt.title(f\"Time evolution of {state_of_interest}\", fontsize=16, fontweight=\"bold\")\n",
    "plt.tick_params(axis=\"both\", which=\"major\", labelsize=12)\n",
    "plt.legend(loc=\"upper right\", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot parameters\n",
    "parameter_of_interest = random.sample(list(test_results[basin_to_analyze][\"parameters\"].keys()), 1)[0]\n",
    "\n",
    "parameters = test_results[basin_to_analyze][\"parameters\"][parameter_of_interest]\n",
    "for i in range(parameters.shape[1]):\n",
    "    plt.plot(\n",
    "        test_results[basin_to_analyze][\"discharges\"][\"y_obs\"].index,\n",
    "        parameters[:, i],\n",
    "        label=parameter_of_interest + \"_\" + str(i + 1),\n",
    "        alpha=0.8,\n",
    "    )\n",
    "\n",
    "# Adding labels and legend\n",
    "plt.xlabel(\"Date\", fontsize=12, fontweight=\"bold\")\n",
    "plt.ylabel(f\"{parameter_of_interest}\", fontsize=12, fontweight=\"bold\")\n",
    "plt.title(f\"Time evolution of {parameter_of_interest}\", fontsize=16, fontweight=\"bold\")\n",
    "plt.tick_params(axis=\"both\", which=\"major\", labelsize=12)\n",
    "plt.legend(loc=\"upper right\", fontsize=12)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.2-0.m111",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.2-0:m111"
  },
  "kernelspec": {
   "display_name": "hy2dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
