{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**General Description**\n",
    "\n",
    "The following notebook contains the code to create, train, validate, and test a rainfall-runoff model using an LSTM network architecture. The notebook support running experiments in different large-sample hydrology datasets including: CAMELS-GB, CAMELS-US, CAMELS-DE. The details for each dataset can be read from a .yml file.\n",
    "\n",
    "***Authors:***\n",
    "- Eduardo Acuña Espinoza (eduardo.espinoza@kit.edu)\n",
    "- Manuel Alvarez Chaves (manuel.alvarez-chaves@simtech.uni-stuttgart.de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import datetime\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Import classes and functions from other files\n",
    "from hy2dl.datasetzoo import get_dataset\n",
    "from hy2dl.evaluation.metrics import nse\n",
    "from hy2dl.modelzoo import get_model\n",
    "from hy2dl.training.loss import nse_basin_averaged\n",
    "from hy2dl.utils.config import Config\n",
    "from hy2dl.utils.optimizer import Optimizer\n",
    "from hy2dl.utils.utils import set_random_seed, upload_to_device\n",
    "\n",
    "# colorblind friendly palette\n",
    "color_palette = {\"observed\": \"#377eb8\", \"simulated\": \"#4daf4a\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1. Initialize information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to .yml file where the experiment settings are stored. The experimet settings can also be defined manually as a\n",
    "# dictionary.\n",
    "# path_experiment_settings = \"../examples/camels_gb.yml\"\n",
    "path_experiment_settings = \"../examples/mfLSTM_camels_us_hourly_ForcingsPerFreq.yml\"\n",
    "\n",
    "# Read experiment settings\n",
    "config = Config(path_experiment_settings)\n",
    "config.init_experiment()\n",
    "config.dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2. Create datasets and dataloaders used to train/validate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset class\n",
    "Dataset = get_dataset(config)\n",
    "\n",
    "# Dataset training\n",
    "config.logger.info(f\"Loading training data from {config.dataset} dataset\")\n",
    "total_time = time.time()\n",
    "\n",
    "training_dataset = Dataset(cfg=config, time_period=\"training\")\n",
    "\n",
    "training_dataset.calculate_basin_std()\n",
    "training_dataset.calculate_global_statistics(save_scaler=True)\n",
    "training_dataset.standardize_data()\n",
    "\n",
    "config.logger.info(f\"Number of entities with valid samples: {len(training_dataset.df_ts)}\")\n",
    "config.logger.info(\n",
    "    f\"Time required to process {len(training_dataset.df_ts)} entities: \"\n",
    "    f\"{datetime.timedelta(seconds=int(time.time() - total_time))}\"\n",
    ")\n",
    "config.logger.info(f\"Number of valid training samples: {len(training_dataset)}\\n\")\n",
    "\n",
    "# Dataloader training\n",
    "train_loader = DataLoader(\n",
    "    dataset=training_dataset,\n",
    "    batch_size=config.batch_size_training,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    collate_fn=training_dataset.collate_fn,\n",
    "    num_workers=config.num_workers,\n",
    ")\n",
    "\n",
    "# Print details of a loader´s sample to check that the format is correct\n",
    "config.logger.info(\"Details training dataloader\".center(60, \"-\"))\n",
    "config.logger.info(f\"Batch structure (number of batches: {len(train_loader)})\")\n",
    "config.logger.info(f\"{'Key':^30}|{'Shape':^30}\")\n",
    "# config.logger.info(\"-\" * 60)\n",
    "# Loop through the sample dictionary and print the shape of each element\n",
    "for key, value in next(iter(train_loader)).items():\n",
    "    if key.startswith((\"x_d\", \"x_conceptual\")):\n",
    "        config.logger.info(f\"{key}\")\n",
    "        for i, v in value.items():\n",
    "            config.logger.info(f\"{i:^30}|{str(v.shape):^30}\")\n",
    "    else:\n",
    "        config.logger.info(f\"{key:<30}|{str(value.shape):^30}\")\n",
    "\n",
    "config.logger.info(\"\")  # prints a blank line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In evaluation (validation and testing) we will create an individual dataset per basin\n",
    "config.logger.info(f\"Loading validation data from {config.dataset} dataset\")\n",
    "entities_ids = np.loadtxt(config.path_entities_validation, dtype=\"str\").tolist()\n",
    "iterator = tqdm(\n",
    "    [entities_ids] if isinstance(entities_ids, str) else entities_ids,\n",
    "    desc=\"Processing entities\",\n",
    "    unit=\"entity\",\n",
    "    ascii=True,\n",
    ")\n",
    "\n",
    "total_time = time.time()\n",
    "validation_dataset = {}\n",
    "for entity in iterator:\n",
    "    dataset = Dataset(cfg=config, time_period=\"validation\", check_NaN=False, entities_ids=entity)\n",
    "\n",
    "    dataset.scaler = training_dataset.scaler\n",
    "    dataset.standardize_data(standardize_output=False)\n",
    "    validation_dataset[entity] = dataset\n",
    "\n",
    "config.logger.info(\n",
    "    f\"Time required to process {len(iterator)} entities: {datetime.timedelta(seconds=int(time.time() - total_time))}\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 3. Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "set_random_seed(cfg=config)\n",
    "model = get_model(config).to(config.device)\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = Optimizer(cfg=config, model=model)\n",
    "\n",
    "# Training report structure\n",
    "config.logger.info(\"Training model\".center(60, \"-\"))\n",
    "config.logger.info(f\"{'':^16}|{'Trainining':^21}|{'Validation':^21}|\")\n",
    "config.logger.info(f\"{'Epoch':^5}|{'LR':^10}|{'Loss':^10}|{'Time':^10}|{'Metric':^10}|{'Time':^10}|\")\n",
    "\n",
    "total_time = time.time()\n",
    "# Loop through epochs\n",
    "for epoch in range(1, config.epochs + 1):\n",
    "    train_time = time.time()\n",
    "    running_loss = 0.0\n",
    "    # Training -------------------------------------------------------------------------------------------------------\n",
    "    model.train()\n",
    "    # Loop through the different batches in the training dataset\n",
    "    iterator = tqdm(\n",
    "        train_loader, desc=f\"Epoch {epoch}/{config.epochs}. Training\", unit=\"batches\", ascii=True, leave=False\n",
    "    )\n",
    "\n",
    "    for idx, sample in enumerate(iterator):\n",
    "        # reach maximum iterations per epoch\n",
    "        if config.max_updates_per_epoch is not None and idx >= config.max_updates_per_epoch:\n",
    "            break\n",
    "\n",
    "        sample = upload_to_device(sample, config.device)  # upload tensors to device\n",
    "        optimizer.optimizer.zero_grad()  # sets gradients to zero\n",
    "\n",
    "        # Forward pass of the model\n",
    "        pred = model(sample)\n",
    "        # Calcuate loss\n",
    "        loss = nse_basin_averaged(y_sim=pred[\"y_hat\"], y_obs=sample[\"y_obs\"], per_basin_target_std=sample[\"std_basin\"])\n",
    "\n",
    "        # Backpropagation (calculate gradients)\n",
    "        loss.backward()\n",
    "\n",
    "        # Update model parameters (e.g, weights and biases)\n",
    "        optimizer.clip_grad_and_step(epoch, idx)\n",
    "\n",
    "        # Keep track of the loss evolution\n",
    "        running_loss += (loss.detach().item() - running_loss) / (idx + 1)\n",
    "        iterator.set_postfix({\"average loss\": f\"{running_loss:.3f}\"})\n",
    "\n",
    "        # remove elements from cuda to free memory\n",
    "        del sample, pred\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # training report\n",
    "    lr = optimizer.optimizer.param_groups[0][\"lr\"]\n",
    "    train_duration = str(datetime.timedelta(seconds=int(time.time() - train_time)))\n",
    "    report = f\"{epoch:^5}|{lr:^10.5f}|{running_loss:^10.3f}|{train_duration:^10}|\"\n",
    "\n",
    "    # Validation -----------------------------------------------------------------------------------------------------\n",
    "    if epoch % config.validate_every == 0:\n",
    "        val_time = time.time()\n",
    "        model.eval()\n",
    "        validation_results = {}\n",
    "        with torch.no_grad():\n",
    "            # If we define validate_n_random_basins as 0 or negative, we take all the basins. Otherwise, we randomly\n",
    "            # select the number of basins defined in validate_n_random_basins\n",
    "            if config.validate_n_random_basins <= 0:\n",
    "                validation_basin_ids = validation_dataset.keys()\n",
    "            else:\n",
    "                validation_basin_ids = random.sample(list(validation_dataset.keys()), config.validate_n_random_basins)\n",
    "\n",
    "            # Go through each basin\n",
    "            iterator = tqdm(\n",
    "                validation_basin_ids,\n",
    "                desc=f\"Epoch {epoch}/{config.epochs}. Validation\",\n",
    "                unit=\"basins\",\n",
    "                ascii=True,\n",
    "                leave=False,\n",
    "            )\n",
    "\n",
    "            for basin in iterator:\n",
    "                loader = DataLoader(\n",
    "                    dataset=validation_dataset[basin],\n",
    "                    batch_size=config.batch_size_evaluation,\n",
    "                    shuffle=False,\n",
    "                    drop_last=False,\n",
    "                    collate_fn=validation_dataset[basin].collate_fn,\n",
    "                    num_workers=config.num_workers,\n",
    "                )\n",
    "\n",
    "                df_ts = pd.DataFrame()\n",
    "                for sample in loader:\n",
    "                    sample = upload_to_device(sample, config.device)\n",
    "                    # Forward pass of the model\n",
    "                    pred = model(sample)\n",
    "                    # Backtransform information (unstandardize the output)\n",
    "                    y_std = validation_dataset[basin].scaler[\"y_std\"].to(config.device)\n",
    "                    y_mean = validation_dataset[basin].scaler[\"y_mean\"].to(config.device)\n",
    "                    y_sim = pred[\"y_hat\"] * y_std + y_mean\n",
    "\n",
    "                    # join results in a dataframe (easier to evaluate/plot later)\n",
    "                    df = pd.DataFrame(\n",
    "                        {\"y_obs\": sample[\"y_obs\"].flatten().cpu().detach(), \"y_sim\": y_sim.flatten().cpu().detach()},\n",
    "                        index=pd.to_datetime(sample[\"date\"].flatten()),\n",
    "                    )\n",
    "\n",
    "                    df_ts = pd.concat([df_ts, df], axis=0)\n",
    "\n",
    "                    # remove elements from cuda to free memory\n",
    "                    del sample, pred, y_sim\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "                validation_results[basin] = df_ts\n",
    "\n",
    "            # average loss validation\n",
    "            loss_validation = nse(df_results=validation_results)\n",
    "            report += f\"{loss_validation:^10.3f}|{str(datetime.timedelta(seconds=int(time.time() - val_time))):^10}|\"\n",
    "\n",
    "    # No validation\n",
    "    else:\n",
    "        report += f\"{'':^10}|{'':^10}|\"\n",
    "\n",
    "    # Print report and save model\n",
    "    config.logger.info(report)\n",
    "    torch.save(model.state_dict(), config.path_save_folder / \"model\" / f\"model_epoch_{epoch}\")\n",
    "    # modify learning rate\n",
    "    optimizer.update_optimizer_lr(epoch=epoch)\n",
    "\n",
    "# print total training time\n",
    "config.logger.info(f\"Total training time: {datetime.timedelta(seconds=int(time.time() - total_time))}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 4. Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case I already trained an LSTM I can re-construct the model. I just need to define the epoch for which I want to\n",
    "# re-construct the model\n",
    "# model = get_model(config).to(config.device)\n",
    "# model.load_state_dict(torch.load(config.path_save_folder / \"model\" / \"model_epoch_20\", map_location=config.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read previously generated scaler\n",
    "with open(config.path_save_folder / \"scaler.pickle\", \"rb\") as file:\n",
    "    scaler = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In evaluation (validation and testing) we will create an individual dataset per basin\n",
    "config.logger.info(f\"Loading testing data from {config.dataset} dataset\")\n",
    "\n",
    "entities_ids = np.loadtxt(config.path_entities_testing, dtype=\"str\").tolist()\n",
    "iterator = tqdm(\n",
    "    [entities_ids] if isinstance(entities_ids, str) else entities_ids,\n",
    "    desc=\"Processing entities\",\n",
    "    unit=\"entity\",\n",
    "    ascii=True,\n",
    ")\n",
    "\n",
    "total_time = time.time()\n",
    "testing_dataset = {}\n",
    "for entity in iterator:\n",
    "    dataset = Dataset(cfg=config, time_period=\"testing\", check_NaN=False, entities_ids=entity)\n",
    "\n",
    "    dataset.scaler = scaler\n",
    "    dataset.standardize_data(standardize_output=False)\n",
    "    testing_dataset[entity] = dataset\n",
    "\n",
    "config.logger.info(\n",
    "    f\"Time required to process {len(iterator)} entities: {datetime.timedelta(seconds=int(time.time() - total_time))}\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.logger.info(\"Testing model\".center(60, \"-\"))\n",
    "total_time = time.time()\n",
    "\n",
    "model.eval()\n",
    "test_results = {}\n",
    "with torch.no_grad():\n",
    "    # Go through each basin\n",
    "    iterator = tqdm(testing_dataset, desc=\"Testing\", unit=\"basins\", ascii=True)\n",
    "    for basin in iterator:\n",
    "        loader = DataLoader(\n",
    "            dataset=testing_dataset[basin],\n",
    "            batch_size=config.batch_size_evaluation,\n",
    "            shuffle=False,\n",
    "            drop_last=False,\n",
    "            collate_fn=testing_dataset[basin].collate_fn,\n",
    "            num_workers=config.num_workers,\n",
    "        )\n",
    "\n",
    "        df_ts = pd.DataFrame()\n",
    "        for sample in loader:\n",
    "            sample = upload_to_device(sample, config.device)  # upload tensors to device\n",
    "            pred = model(sample)\n",
    "            # backtransformed information\n",
    "            y_sim = pred[\"y_hat\"] * testing_dataset[basin].scaler[\"y_std\"].to(config.device) + (\n",
    "                testing_dataset[basin].scaler[\"y_mean\"].to(config.device)\n",
    "            )\n",
    "\n",
    "            # join results in a dataframe and store them in a dictionary (is easier to plot later)\n",
    "            df = pd.DataFrame(\n",
    "                {\"y_obs\": sample[\"y_obs\"].flatten().cpu().detach(), \"y_sim\": y_sim.flatten().cpu().detach()},\n",
    "                index=pd.to_datetime(sample[\"date\"].flatten()),\n",
    "            )\n",
    "\n",
    "            df_ts = pd.concat([df_ts, df], axis=0)\n",
    "\n",
    "            # remove from cuda\n",
    "            del sample, pred, y_sim\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        test_results[basin] = df_ts\n",
    "\n",
    "# Save results as a pickle file\n",
    "with open(config.path_save_folder / \"test_results.pickle\", \"wb\") as f:\n",
    "    pickle.dump(test_results, f)\n",
    "\n",
    "config.logger.info(f\"Total testing time: {datetime.timedelta(seconds=int(time.time() - total_time))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 5. Initial analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss testing\n",
    "loss_testing = nse(df_results=test_results, average=False)\n",
    "df_NSE = pd.DataFrame(data={\"basin_id\": testing_dataset.keys(), \"NSE\": np.round(loss_testing, 3)})\n",
    "df_NSE = df_NSE.set_index(\"basin_id\")\n",
    "df_NSE.to_csv(config.path_save_folder / \"NSE_testing.csv\", index=True, header=True)\n",
    "\n",
    "# Plot the histogram\n",
    "plt.hist(df_NSE[\"NSE\"], bins=[0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])\n",
    "\n",
    "# Add NSE statistics to the plot\n",
    "plt.text(\n",
    "    0.01,\n",
    "    0.8,\n",
    "    (\n",
    "        f\"Mean: {'%.2f' % df_NSE['NSE'].mean():>7}\\n\"\n",
    "        f\"Median: {'%.2f' % df_NSE['NSE'].median():>0}\\n\"\n",
    "        f\"Max: {'%.2f' % df_NSE['NSE'].max():>9}\\n\"\n",
    "        f\"Min: {'%.2f' % df_NSE['NSE'].min():>10}\"\n",
    "    ),\n",
    "    transform=plt.gca().transAxes,\n",
    "    bbox=dict(facecolor=\"white\", alpha=0.5),\n",
    ")\n",
    "\n",
    "# Format plot\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 5)\n",
    "plt.xlabel(\"NSE\", fontsize=12, fontweight=\"bold\")\n",
    "plt.ylabel(\"Frequency\", fontsize=12, fontweight=\"bold\")\n",
    "plt.title(\"NSE Histogram\", fontsize=16, fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot simulated and observed discharges\n",
    "basin_to_analyze = random.sample(list(test_results.keys()), 1)[0]\n",
    "\n",
    "plt.figure(figsize=(20, 7))\n",
    "plt.plot(test_results[basin_to_analyze][\"y_obs\"], label=\"observed\", color=color_palette[\"observed\"])\n",
    "plt.plot(test_results[basin_to_analyze][\"y_sim\"], label=\"simulated\", alpha=0.5, color=color_palette[\"simulated\"])\n",
    "\n",
    "# Format plot\n",
    "plt.xlabel(\"Date\", fontsize=12, fontweight=\"bold\")\n",
    "plt.ylabel(\"Discharge [mm/d]\", fontsize=12, fontweight=\"bold\")\n",
    "plt.title(\"Modeling results\", fontsize=16, fontweight=\"bold\")\n",
    "plt.tick_params(axis=\"both\", which=\"major\", labelsize=12)\n",
    "plt.legend(loc=\"upper right\", fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.2-0.m111",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.2-0:m111"
  },
  "kernelspec": {
   "display_name": "hy2dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
